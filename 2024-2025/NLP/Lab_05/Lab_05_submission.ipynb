{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Read The Dataset and Apply The Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/simpsons_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no actually it was a little of both sometimes ...</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheres mr bergstrom</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont know although id sure like to talk to h...</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that life is worth living</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the polls will be open from now until the end ...</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  no actually it was a little of both sometimes ...   \n",
       "1                                wheres mr bergstrom   \n",
       "2  i dont know although id sure like to talk to h...   \n",
       "3                          that life is worth living   \n",
       "4  the polls will be open from now until the end ...   \n",
       "\n",
       "                                        spoken_words  \n",
       "0  No, actually, it was a little of both. Sometim...  \n",
       "1                             Where's Mr. Bergstrom?  \n",
       "2  I don't know. Although I'd sure like to talk t...  \n",
       "3                         That life is worth living.  \n",
       "4  The polls will be open from now until the end ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=[\"spoken_words\"], inplace=True)\n",
    "df[\"cleaned_text\"] = df[\"spoken_words\"].apply(clean_text)\n",
    "df[[\"cleaned_text\", \"spoken_words\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[\"cleaned_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for i in data:\n",
    "    token = word_tokenize(i)\n",
    "    tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    tokens,\n",
    "    min_count=1,\n",
    "    vector_size=120,\n",
    "    window=8,\n",
    "    sg=1,\n",
    "    workers=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Find similar words using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(\n",
    "    word: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    ") -> list:\n",
    "    similar = model.wv.most_similar(word)\n",
    "    return similar\n",
    "\n",
    "\n",
    "def print_most_similar(\n",
    "    word: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    ") -> None:\n",
    "    print(f\"Most Similar word to '{word}' is: \")\n",
    "    for i in most_similar(word, model):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar word to 'homer' is: \n",
      "('abe', 0.8551385998725891)\n",
      "('marge', 0.8428040146827698)\n",
      "('bartholomew', 0.8117152452468872)\n",
      "('barney', 0.7930422425270081)\n",
      "('karl', 0.7785205841064453)\n",
      "('grampa', 0.7784044742584229)\n",
      "('cooties', 0.7783496975898743)\n",
      "('lurleen', 0.7759321928024292)\n",
      "('eliza', 0.7751312255859375)\n",
      "('herb', 0.7743209004402161)\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"homer\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar word to 'marge' is: \n",
      "('homer', 0.842803955078125)\n",
      "('abe', 0.8176416158676147)\n",
      "('sweetie', 0.7895161509513855)\n",
      "('sweetheart', 0.7819197177886963)\n",
      "('maude', 0.7737510800361633)\n",
      "('honey', 0.7725657820701599)\n",
      "('blanche', 0.7671554684638977)\n",
      "('becky', 0.7669074535369873)\n",
      "('marjorie', 0.7643067240715027)\n",
      "('allison', 0.7614040374755859)\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"marge\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar word to 'bart' is: \n",
      "('lisa', 0.8110323548316956)\n",
      "('jessica', 0.7966541051864624)\n",
      "('milhouse', 0.7905529737472534)\n",
      "('grampa', 0.7844950556755066)\n",
      "('abe', 0.7810661196708679)\n",
      "('saxophone', 0.7726356387138367)\n",
      "('eliza', 0.7610217332839966)\n",
      "('bartholomew', 0.7591866850852966)\n",
      "('janey', 0.7553672194480896)\n",
      "('jimbo', 0.7542879581451416)\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"bart\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Similar word to 'bart' is: \n",
      "('lisa', 0.8110323548316956)\n",
      "('jessica', 0.7966541051864624)\n",
      "('milhouse', 0.7905529737472534)\n",
      "('grampa', 0.7844950556755066)\n",
      "('abe', 0.7810661196708679)\n",
      "('saxophone', 0.7726356387138367)\n",
      "('eliza', 0.7610217332839966)\n",
      "('bartholomew', 0.7591866850852966)\n",
      "('janey', 0.7553672194480896)\n",
      "('jimbo', 0.7542879581451416)\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"bart\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Similarity between two words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(\n",
    "    word1: str,\n",
    "    word2: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    ") -> float:\n",
    "    return model.wv.similarity(word1, word2)\n",
    "\n",
    "\n",
    "def print_cosine_similarity(\n",
    "    word1: str,\n",
    "    word2: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    ") -> None:\n",
    "    print(f\"Cosine Similarity between '{word1}' and '{word2}' is: {similarity(word1, word2, model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'moes' and 'tavern' is: 0.8600816130638123\n",
      "Cosine Similarity between 'maggie' and 'baby' is: 0.6984161138534546\n",
      "Cosine Similarity between 'bart' and 'nelson' is: 0.7291463017463684\n"
     ]
    }
   ],
   "source": [
    "print_cosine_similarity(\"moes\", \"tavern\", model)\n",
    "print_cosine_similarity(\"maggie\", \"baby\", model)\n",
    "print_cosine_similarity(\"bart\", \"nelson\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Doesn't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_not_match(\n",
    "    words,\n",
    "    model: gensim.models.Word2Vec,\n",
    "):\n",
    "    return model.wv.doesnt_match(words)\n",
    "\n",
    "\n",
    "def print_does_not_match(\n",
    "    words,\n",
    "    model: gensim.models.Word2Vec,\n",
    "):\n",
    "    print(f\"The word that does not match in the list '{words}' is: {does_not_match(words, model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word that does not match in the list '['jimbo', 'milhouse', 'kearney']' is: milhouse\n",
      "The word that does not match in the list '['nelson', 'bart', 'milhouse']' is: nelson\n",
      "The word that does not match in the list '['bart', 'homer', 'milhouse']' is: homer\n"
     ]
    }
   ],
   "source": [
    "print_does_not_match(\n",
    "    words=[\"jimbo\", \"milhouse\", \"kearney\"],\n",
    "    model=model,\n",
    ")\n",
    "print_does_not_match(\n",
    "    words=[\"nelson\", \"bart\", \"milhouse\"],\n",
    "    model=model,\n",
    ")\n",
    "print_does_not_match(\n",
    "    words=[\"bart\", \"homer\", \"milhouse\"],\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5.1: Which word is to woman as homer is to marge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogy(\n",
    "    word1: str,\n",
    "    word2: str,\n",
    "    word_to_compare: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    "):\n",
    "    return model.wv.most_similar(positive=[word1, word_to_compare], negative=[word2], topn=3)\n",
    "\n",
    "\n",
    "def print_analogy(\n",
    "    word1: str,\n",
    "    word2: str,\n",
    "    word_to_compare: str,\n",
    "    model: gensim.models.Word2Vec,\n",
    "):\n",
    "    print(f\"Analogy: {word1} is to {word2} as {word_to_compare} is to: \")\n",
    "    for i in analogy(word1, word2, word_to_compare, model):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy: homer is to marge as woman is to: \n",
      "('bear', 0.760161817073822)\n",
      "('hostage', 0.7541569471359253)\n",
      "('grimes', 0.7411158680915833)\n"
     ]
    }
   ],
   "source": [
    "print_analogy(\n",
    "    word1=\"homer\",\n",
    "    word2=\"marge\",\n",
    "    word_to_compare=\"woman\",\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5.2: Which word is to woman as bart is to man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy: bart is to man as woman is to: \n",
      "('lisa', 0.7667612433433533)\n",
      "('herself', 0.7279494404792786)\n",
      "('juliet', 0.7161649465560913)\n"
     ]
    }
   ],
   "source": [
    "print_analogy(\n",
    "    word1=\"bart\",\n",
    "    word2=\"man\",\n",
    "    word_to_compare=\"woman\",\n",
    "    model=model,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP-class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
